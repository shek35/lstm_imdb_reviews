{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e28f7c45-f3f5-45b8-8b41-5012bc57d4bd",
      "metadata": {
        "id": "e28f7c45-f3f5-45b8-8b41-5012bc57d4bd"
      },
      "source": [
        "Goals:\n",
        "- understand the difficulties of counting and probabilities in NLP applications\n",
        "- work with real world data using different approaches to classification\n",
        "- stress test your model (to some extent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfc3f1aa-6b6e-4953-a30d-a79ab0794170",
      "metadata": {
        "id": "cfc3f1aa-6b6e-4953-a30d-a79ab0794170"
      },
      "source": [
        "Name: __Abhishek Rao__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c281567d-b99b-45df-8b1b-2b0e35cb9196",
      "metadata": {
        "id": "c281567d-b99b-45df-8b1b-2b0e35cb9196"
      },
      "source": [
        "This is about the __provided__ movie review data set.\n",
        "\n",
        "1. Where did you get the data from? The provided dataset(s) were sub-sampled from https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
        "2. (1 pt) How was the data collected (where did the people acquiring the data get it from and how)?\n",
        "The data was collected from IMDB reviews of movies\n",
        "\n",
        "3. (2 pts) How large is the dataset (answer for both the train and the dev set, separately)? (# reviews, # tokens in both the train and dev sets)\n",
        "Ans: DEV-Total Reviews: 200\n",
        "Total Tokens: 47158\n",
        "\n",
        "      TRAIN-Total Reviews: 1600\n",
        "Total Tokens: 369136\n",
        "\n",
        "4. (1 pt) What is your data? (i.e. newswire, tweets, books, blogs, etc)\n",
        "The data was collected from IMDB reviews movies\n",
        "\n",
        "5. (1 pt) Who produced the data? (who were the authors of the text? Your answer might be a specific person or a particular group of people)\n",
        "The authors of the data are the people that watched movies and had polarizing views on it.\n",
        "6. (2 pts) What is the distribution of labels in the data (answer for both the train and the dev set, separately)?\n",
        "\n",
        "Ans:\n",
        "\n",
        "        DEV- Sentiment\n",
        "                1    105\n",
        "                0     95\n",
        "\n",
        "        TRAIN-Sentiment\n",
        "                1    804\n",
        "                0    796\n",
        "7. (2 pts) How large is the vocabulary (answer for both the train and the dev set, separately)?\n",
        "\n",
        "Ans:\n",
        "\n",
        "      DEV-Vocabulary Size: 11000\n",
        "\n",
        "      TRAIN- Vocabulary Size: 44008\n",
        "8. (1 pt) How big is the overlap between the vocabulary for the train and dev set?\n",
        "\n",
        "Ans:\n",
        "\n",
        "      Vocabulary Overlap Size: 6973\n",
        "\n",
        "      Overlap as a percentage of Training Vocabulary: 15.84%\n",
        "\n",
        "      Overlap as a percentage of Development Vocabulary: 63.39%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "0z43Eo1qS9Av",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z43Eo1qS9Av",
        "outputId": "8d45a5b3-cee4-495d-9841-4ec4f50f1ea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary Overlap Size: 6973\n",
            "Overlap as a percentage of Training Vocabulary: 15.84%\n",
            "Overlap as a percentage of Development Vocabulary: 63.39%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from math import log\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "train_file_path = 'movie_reviews_train.txt'\n",
        "train_data = pd.read_csv(train_file_path, sep=\"\\t\", header=None, names=['ID', 'Review', 'Sentiment'])\n",
        "train_data['Tokens'] = train_data['Review'].apply(lambda x: x.lower().split())\n",
        "train_vocab = set(word for review in train_data['Tokens'] for word in review)\n",
        "\n",
        "dev_file_path = 'movie_reviews_dev.txt'\n",
        "dev_data = pd.read_csv(dev_file_path, sep=\"\\t\", header=None, names=['ID', 'Review', 'Sentiment'])\n",
        "dev_data['Tokens'] = dev_data['Review'].apply(lambda x: x.lower().split())\n",
        "dev_vocab = set(word for review in dev_data['Tokens'] for word in review)\n",
        "\n",
        "vocab_overlap = train_vocab.intersection(dev_vocab)\n",
        "overlap_size = len(vocab_overlap)\n",
        "\n",
        "print(f\"Vocabulary Overlap Size: {overlap_size}\")\n",
        "print(f\"Overlap as a percentage of Training Vocabulary: {100 * overlap_size / len(train_vocab):.2f}%\")\n",
        "print(f\"Overlap as a percentage of Development Vocabulary: {100 * overlap_size / len(dev_vocab):.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "0e9bbb93-9a5d-4326-8dd0-d2ffcf242123",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e9bbb93-9a5d-4326-8dd0-d2ffcf242123",
        "outputId": "cde1b37f-f1d3-4a76-d910-c477bed99ebc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import f1_score\n",
        "from collections import Counter\n",
        "import time\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "62c515ae-3637-42b6-9412-e0710e7821bb",
      "metadata": {
        "id": "62c515ae-3637-42b6-9412-e0710e7821bb"
      },
      "outputs": [],
      "source": [
        "# The following function reads a data-file and splits the contents by tabs.\n",
        "# The first column is an ID, and thus is discarded. The second column consists of the actual reviews data.\n",
        "# The third column is the true label for each data point.\n",
        "\n",
        "# The function returns two objects - a list of all reviews, and a numpy array of labels.\n",
        "# You will need to use this function later.\n",
        "\n",
        "def get_lists(input_file):\n",
        "    f=open(input_file, 'r')\n",
        "    lines = [line.split('\\t')[1:] for line in f.readlines()]\n",
        "    X = [row[0] for row in lines]\n",
        "    y=np.array([int(row[1]) for row in lines])\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# If the vocabulary argument is supplied, then the function should only convert the input corpus\n",
        "# to feature vectors using the provided vocabulary and the max_features argument (if not None).\n",
        "# In this case, the function should return feature vectors and the supplied vocabulary.\n",
        "\n",
        "# If the max_features parameter is set to None, then all words in the corpus should be used.\n",
        "# If the max_features parameter is specified (say, k),\n",
        "# then only use the k most frequent words in the corpus to build your vocabulary.\n",
        "\n",
        "# The function should return two things.\n",
        "\n",
        "# The first object should be a numpy array of shape (n_documents, vocab_size),\n",
        "# which contains the TF-IDF feature vectors for each document.\n",
        "\n",
        "# The second object should be a dictionary of the words in the vocabulary,\n",
        "# mapped to their corresponding index in alphabetical sorted order.\n",
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "def get_tfidf_vectors(token_lists, max_features=None, vocabulary=None):\n",
        "\n",
        "    doc_freqs = defaultdict(int)\n",
        "\n",
        "    lowercase = [token_list.lower() for token_list in token_lists]\n",
        "    token_lists = lowercase\n",
        "\n",
        "    # Create a vocabulary from the corpus if it's not provided\n",
        "    if vocabulary is None:\n",
        "        vocab = set()\n",
        "        for token_list in token_lists:\n",
        "            tokens = nltk.word_tokenize(token_list)\n",
        "            for token in tokens:\n",
        "                if token not in vocab:\n",
        "                    vocab.add(token)\n",
        "        vocab = sorted(vocab)\n",
        "\n",
        "        # Limit the vocabulary size if max_features is specified\n",
        "        if max_features is not None:\n",
        "            vocab = vocab[:max_features]\n",
        "    else:\n",
        "        vocab = vocabulary\n",
        "\n",
        "    n_docs = len(token_lists)\n",
        "    vocab_size = len(vocab)\n",
        "    vocab_index = {term: i for i, term in enumerate(vocab)}\n",
        "\n",
        "    # Calculate term frequencies and document frequencies in one pass\n",
        "    tf = np.zeros((n_docs, vocab_size), dtype=np.float32)\n",
        "    doc_freqs = np.zeros(vocab_size, dtype=np.float32)\n",
        "    for i, doc in enumerate(token_lists):\n",
        "        tokens = doc.split()\n",
        "        term_freqs = Counter(tokens)\n",
        "        doc_length = len(tokens)\n",
        "        for term in term_freqs:\n",
        "            if term in vocab_index:\n",
        "                j = vocab_index[term]\n",
        "                # tf[i, j] = term_freqs[term] / doc_length\n",
        "                # doc_freqs[j] += 1\n",
        "                tf_scale = 1 + math.log(term_freqs[term]) # Scale term freq within doc\n",
        "                tf_scale /= doc_length\n",
        "                tf[i, j] = tf_scale\n",
        "                doc_freqs[j] += 1\n",
        "\n",
        "    # Calculate inverse document frequencies\n",
        "    idf = np.log(n_docs / (1 + doc_freqs)) + 1\n",
        "\n",
        "    # Calculate TF-IDF\n",
        "    tfidf = tf * idf[None, :]\n",
        "    # epsilon = 1e-8  # Small constant to avoid division by zero\n",
        "    # tfidf_norm = np.linalg.norm(tfidf, axis=1, keepdims=True)\n",
        "    # tfidf_norm[tfidf_norm == 0] = epsilon  # Replace zero norms with epsilon\n",
        "    # tfidf = tfidf / tfidf_norm\n",
        "\n",
        "    return tfidf, vocab_index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62226f12-d0e5-4e74-887e-5cd852b96707",
      "metadata": {
        "id": "62226f12-d0e5-4e74-887e-5cd852b96707"
      },
      "source": [
        "We will now compare the runtime of our Tf-Idf implementation to the `sklearn` implementation. Call the respective functions with appropriate arguments in the code block below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "e2e6c726-0e12-4e1f-8c8b-146a9a506a3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2e6c726-0e12-4e1f-8c8b-146a9a506a3f",
        "outputId": "a441e4b8-f1df-4e4c-fb04-66a544de7ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken:  4.23777437210083  seconds\n",
            "Time taken:  0.42064905166625977  seconds\n"
          ]
        }
      ],
      "source": [
        "# define constants for the files we are using\n",
        "TRAIN_FILE = \"movie_reviews_train.txt\"\n",
        "TEST_FILE = \"movie_reviews_test.txt\"\n",
        "\n",
        "train_corpus, y_train = get_lists(TRAIN_FILE)\n",
        "\n",
        "# First we will use our custom vectorizer to convert words to features, and time it.\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "X_train_custom, vocab_custom = get_tfidf_vectors(train_corpus)\n",
        "end = time.time()\n",
        "\n",
        "print(\"Time taken: \", end-start, \" seconds\")\n",
        "\n",
        "# Next we will use sklearn's TfidfVectorizer to load in the data, and time it.\n",
        "\n",
        "start = time.time()\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_sklearn = vectorizer.fit_transform(train_corpus)\n",
        "end = time.time()\n",
        "\n",
        "print(\"Time taken: \", end-start, \" seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35afb9c6",
      "metadata": {
        "id": "35afb9c6"
      },
      "source": [
        "NOTE: Ideally, your vectorizer should be within one order of magnitude of the sklearn implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "8bdbf31c-bf6b-4ab4-b87b-47dd7c5468a8",
      "metadata": {
        "id": "8bdbf31c-bf6b-4ab4-b87b-47dd7c5468a8"
      },
      "outputs": [],
      "source": [
        "def calculate_sparsity(X):\n",
        "    num_zero = np.sum(X == 0, axis=1)  # Count zeros in each row (review)\n",
        "    num_features = X.shape[1]  # Total number of features\n",
        "    sparsity_percentages = (num_zero / num_features) * 100  # Percentage of zeros in each review\n",
        "    avg_sparsity_percentage = np.mean(sparsity_percentages)  # Average across all reviews\n",
        "    return avg_sparsity_percentage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "0f6JMVg2EuHy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f6JMVg2EuHy",
        "outputId": "4f343a50-bb85-4f67-bf72-5ed1c7a0f713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of vocab_custom:  27172\n",
            "Length of sklearn vocab:  22601\n",
            "Sparsity of custom features:  99.56511988443987\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-46-fbc7c7ea01f8>:5: SparseEfficiencyWarning: Comparing a sparse matrix with 0 using == is inefficient, try using != instead.\n",
            "  print (\"Sparsity of sklearn features: \", calculate_sparsity(X_train_sklearn))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sparsity of sklearn features:  99.39285042697226\n"
          ]
        }
      ],
      "source": [
        "print (\"Length of vocab_custom: \", len(vocab_custom))\n",
        "print (\"Length of sklearn vocab: \", len(vectorizer.vocabulary_))\n",
        "print (\"Sparsity of custom features: \", calculate_sparsity(X_train_custom))\n",
        "print (\"Sparsity of sklearn features: \", calculate_sparsity(X_train_sklearn))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6463f022-7433-4397-88ed-eed8b01b1a45",
      "metadata": {
        "id": "6463f022-7433-4397-88ed-eed8b01b1a45"
      },
      "source": [
        "1. How large is the vocabulary generated by your vectorizer?<br> **Vocabulary size of custom vectorizer: 27172**\n",
        "2. How large is the vocabulary generated by the `sklearn` TfidfVectorizer?<br> **Vocabulary size of sklearn TfidfVectorizer: 22601**\n",
        "3. Where might these differences be coming from?<br> **The differences in vocabulary sizes could have come from several factors including differences in tokenization methods, handling of stop words, and the treatment of term frequencies (including the handling of rare terms).**\n",
        "4. What steps did you take to ensure your vectorizer is optimized for best possible runtime?<br> **both term frequencies and doc freq were computed in one pass, ans used numpy array operations insead of python defaults; Utilized Python's collections.Counter to efficiently count term frequencies across documents**\n",
        "5. How sparse are your custom features (average percentage of features per review that are zero)?<br> **Sparsity of custom features: 99.56%**\n",
        "6. How sparse are the TfidfVectorizer's features?<br> **99.40%**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f38f496b",
      "metadata": {
        "id": "f38f496b"
      },
      "source": [
        "NOTE: if you set the lowercase option to False, the sklearn vectorizer should have a vocabulary of around 50k words/tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09c76612-4dd4-489c-90e4-0c38029c32d1",
      "metadata": {
        "id": "09c76612-4dd4-489c-90e4-0c38029c32d1"
      },
      "source": [
        "**Logistic Regression**\n",
        "\n",
        "Now, we will compare how our custom features stack up against sklearn's TfidfVectorizer, by training two separate Logistic Regression classifiers - one on each set of feature vectors. Then load the test set, and convert it to two sets of feature vectors, one using our custom vectorizer (to do this, provide the vocabulary as a function argument), and one using sklearn's Tfidf (use the same object as before to transform the test inputs). For both classifiers, print the average accuracy on the test set and the F1 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "68eb6d36-1e71-4665-aab4-1217a42e6dcc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68eb6d36-1e71-4665-aab4-1217a42e6dcc",
        "outputId": "1c484b8c-c884-4bde-e08d-df65f6971cc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score of custom vectorizer:  0.8035714285714286\n",
            "F1 Score of sklearn's TfidfVectorizer:  0.9411764705882354\n"
          ]
        }
      ],
      "source": [
        "\n",
        "lr_custom = LogisticRegression()\n",
        "lr_custom.fit(X_train_custom, y_train)\n",
        "\n",
        "# Load the test data, extract features using your custom vectorizer, and test the performance of the LR classifier\n",
        "\n",
        "test_corpus, y_test = get_lists(TEST_FILE)\n",
        "\n",
        "X_test_custom, _ = get_tfidf_vectors(test_corpus, vocabulary=vocab_custom)\n",
        "y_pred_custom = lr_custom.predict(X_test_custom)\n",
        "\n",
        "# Print the accuracy of your model on the test data\n",
        "\n",
        "accuracy_custom = f1_score(y_test, y_pred_custom)\n",
        "print(\"F1 Score of custom vectorizer: \", accuracy_custom)\n",
        "\n",
        "\n",
        "lr_sklearn = LogisticRegression()\n",
        "lr_sklearn.fit(X_train_sklearn, y_train)\n",
        "\n",
        "X_test_sklearn = vectorizer.transform(test_corpus)\n",
        "y_pred_sklearn = lr_sklearn.predict(X_test_sklearn)\n",
        "\n",
        "accuracy_sklearn = f1_score(y_pred_sklearn, y_pred_custom)\n",
        "print(\"F1 Score of sklearn's TfidfVectorizer: \", accuracy_sklearn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5679888",
      "metadata": {
        "id": "b5679888"
      },
      "source": [
        "NOTE: we're expecting to see a F1 score of around 80% using both your custom features and the sklearn features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0220a93-ba22-411a-962f-983ffe3a34f2",
      "metadata": {
        "id": "f0220a93-ba22-411a-962f-983ffe3a34f2"
      },
      "source": [
        "Finally, repeat the process (training and testing), but this time, set the max_features argument to 1000 for both our custom vectorizer and sklearn's Tfidfvectorizer. Report average accuracy and F1 scores for both classifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f995a09c-0447-422d-8b37-e9120cfadfab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f995a09c-0447-422d-8b37-e9120cfadfab",
        "outputId": "dcd27724-af0c-4ce4-ac97-945b2a6fa4a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 score of custom vectorizer with max_features=1000:  0.6887417218543046\n",
            "F1 score of sklearn's TfidfVectorizer with max_features=1000:  0.8036529680365296\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X_train_custom_1000, vocab_custom_1000 = get_tfidf_vectors(train_corpus, max_features=1000)\n",
        "X_test_custom_1000, _ = get_tfidf_vectors(test_corpus, vocabulary=vocab_custom_1000, max_features=1000)\n",
        "\n",
        "\n",
        "lr_custom_1000 = LogisticRegression()\n",
        "lr_custom_1000.fit(X_train_custom_1000, y_train)\n",
        "y_pred_custom_1000 = lr_custom_1000.predict(X_test_custom_1000)\n",
        "\n",
        "\n",
        "# Print the accuracy of your model on the test data\n",
        "\n",
        "\n",
        "f1_custom_1000 = f1_score(y_test, y_pred_custom_1000)\n",
        "print(\"F1 score of custom vectorizer with max_features=1000: \", f1_custom_1000)\n",
        "\n",
        "\n",
        "# Now repeat the above steps, but this time using features extracted by sklearn's Tfidfvectorizer\n",
        "\n",
        "vectorizer_1000 = TfidfVectorizer(max_features=1000)\n",
        "X_train_sklearn_1000 = vectorizer_1000.fit_transform(train_corpus)\n",
        "X_test_sklearn_1000 = vectorizer_1000.transform(test_corpus)\n",
        "\n",
        "lr_sklearn_1000 = LogisticRegression()\n",
        "lr_sklearn_1000.fit(X_train_sklearn_1000, y_train)\n",
        "y_pred_sklearn_1000 = lr_sklearn_1000.predict(X_test_sklearn_1000)\n",
        "\n",
        "f1_sklearn_1000 = f1_score(y_test, y_pred_sklearn_1000)\n",
        "print(\"F1 score of sklearn's TfidfVectorizer with max_features=1000: \", f1_sklearn_1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2858e409-8a87-43aa-8646-1e5419cce6db",
      "metadata": {
        "id": "2858e409-8a87-43aa-8646-1e5419cce6db"
      },
      "source": [
        "1. Is there a stark difference between the two vectorizers with 1000 features?<br>**Yes**\n",
        "2. Use sklearn's documentation for the Tfidfvectorizer to figure out what may be causing the performance difference (or lack thereof).<br>**idf smoothing, stop words and feature scaling?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68df8d77",
      "metadata": {
        "id": "68df8d77"
      },
      "source": [
        "NOTE: Irrespective of your conclusions, both implementations should be above 60% F1 Score."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c652f8ab-3893-4021-b33f-c466b2e1d98a",
      "metadata": {
        "id": "c652f8ab-3893-4021-b33f-c466b2e1d98a"
      },
      "source": [
        "\n",
        "----\n",
        "1. Using PyTorch, implement a feedforward neural network to do sentiment analysis. This model should take sparse vectors of length 10000 as input (note this is 10000, not 1000), and have a single output with the sigmoid activation function. The number of hidden layers, and intermediate activation choices are up to you, but please make sure your model does not take more than ~1 minute to train.\n",
        "2. Evaluate the model using PyTorch functions for average accuracy, area under the ROC curve and F1 scores (see [torcheval](https://pytorch.org/torcheval/stable/)) using both vectorizers, with max_features set to 10000 in both cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "3f563ec2-d02a-4176-908c-011acd8851de",
      "metadata": {
        "id": "3f563ec2-d02a-4176-908c-011acd8851de"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# if torch.backends.mps.is_available():\n",
        "# \tdevice = torch.device(\"mps\")\n",
        "if torch.cuda.is_available():\n",
        "\tdevice = torch.device(\"cuda\")\n",
        "else:\n",
        "\tdevice = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "fcb6aa45-e33a-4d08-bff8-996e1f80dad2",
      "metadata": {
        "id": "fcb6aa45-e33a-4d08-bff8-996e1f80dad2"
      },
      "outputs": [],
      "source": [
        "class feedforward(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        out = self.fc1(X)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "    def predict(self, X):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            output = self.forward(X)\n",
        "            predicted = (output > 0.5).float()\n",
        "        return predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "ba08e134-2a81-48b9-89c3-43046be4cc1b",
      "metadata": {
        "id": "ba08e134-2a81-48b9-89c3-43046be4cc1b"
      },
      "outputs": [],
      "source": [
        "# Load the data using custom and sklearn vectors\n",
        "\n",
        "X_train_custom = torch.from_numpy(X_train_custom).float().to(device)\n",
        "X_train_sklearn = torch.from_numpy(X_train_sklearn.toarray()).float().to(device)\n",
        "y_train = torch.from_numpy(y_train).float().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "055e1e59-4d96-4a6b-8e16-cd14fcc4b760",
      "metadata": {
        "id": "055e1e59-4d96-4a6b-8e16-cd14fcc4b760"
      },
      "outputs": [],
      "source": [
        "# Create a feedforward neural network model\n",
        "# Adam is an appropriate optimizer for this task\n",
        "\n",
        "\n",
        "input_size_custom = X_train_custom.shape[1]\n",
        "input_size_sklearn = X_train_sklearn.shape[1]\n",
        "hidden_size = 128\n",
        "output_size = 1\n",
        "\n",
        "model_custom = feedforward(input_size_custom, hidden_size, output_size).to(device)\n",
        "model_sklearn = feedforward(input_size_sklearn, hidden_size, output_size).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_custom = torch.optim.Adam(model_custom.parameters())\n",
        "optimizer_sklearn = torch.optim.Adam(model_sklearn.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "237cbc15-3473-427d-8d3f-af1059f736b4",
      "metadata": {
        "id": "237cbc15-3473-427d-8d3f-af1059f736b4"
      },
      "outputs": [],
      "source": [
        "# Train the model for 50 epochs on both custom and sklearn vectors\n",
        "\n",
        "\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    # Custom vectors\n",
        "    model_custom.train()\n",
        "    optimizer_custom.zero_grad()\n",
        "    outputs = model_custom(X_train_custom)\n",
        "    loss = criterion(outputs.squeeze(), y_train)\n",
        "    loss.backward()\n",
        "    optimizer_custom.step()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Sklearn vectors\n",
        "    model_sklearn.train()\n",
        "    optimizer_sklearn.zero_grad()\n",
        "    outputs = model_sklearn(X_train_sklearn)\n",
        "    loss = criterion(outputs.squeeze(), y_train)\n",
        "    loss.backward()\n",
        "    optimizer_sklearn.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "fdf1319f-41c0-4237-982f-b60d492fbbd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdf1319f-41c0-4237-982f-b60d492fbbd7",
        "outputId": "d440e15a-fda7-4902-eb25-b6ef058026a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torcheval in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.11.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torcheval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "_nJ_U81w_T0N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nJ_U81w_T0N",
        "outputId": "ada88b73-2d81-49a4-c560-5584b8f26f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Custom Vectors:\n",
            "Binary F1 Score: 0.7841\n",
            "Binary AUROC: 0.7489\n",
            "Binary Accuracy: 0.7550\n",
            "\n",
            "Sklearn Vectors:\n",
            "Binary F1 Score: 0.7861\n",
            "Binary AUROC: 0.7910\n",
            "Binary Accuracy: 0.7850\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using custom and sklearn vectors\n",
        "\n",
        "model_custom.eval()\n",
        "model_sklearn.eval()\n",
        "\n",
        "\n",
        "from torcheval.metrics.functional import binary_f1_score, binary_auroc, binary_accuracy\n",
        "# Test the model using custom and sklearn vectors\n",
        "# Evaluate the model and report the score using Binary F1 score, Binary AUROC and Binary accuracy\n",
        "\n",
        "X_test_custom = torch.from_numpy(X_test_custom).float().to(device)\n",
        "y_test = torch.from_numpy(y_test).float().to(device)\n",
        "X_test_sklearn = torch.from_numpy(X_test_sklearn.toarray()).float().to(device)\n",
        "\n",
        "y_pred_custom = model_custom.predict(X_test_custom).squeeze()\n",
        "y_pred_sklearn = model_sklearn.predict(X_test_sklearn).squeeze()\n",
        "\n",
        "f1_custom = binary_f1_score(y_pred_custom, y_test)\n",
        "auroc_custom = binary_auroc(y_pred_custom, y_test)\n",
        "accuracy_custom = binary_accuracy(y_pred_custom, y_test)\n",
        "\n",
        "f1_sklearn = binary_f1_score(y_pred_sklearn, y_test)\n",
        "auroc_sklearn = binary_auroc(y_pred_sklearn, y_test)\n",
        "accuracy_sklearn = binary_accuracy(y_pred_sklearn, y_test)\n",
        "\n",
        "print(\"Custom Vectors:\")\n",
        "print(f\"Binary F1 Score: {f1_custom:.4f}\")\n",
        "print(f\"Binary AUROC: {auroc_custom:.4f}\")\n",
        "print(f\"Binary Accuracy: {accuracy_custom:.4f}\")\n",
        "\n",
        "print(\"\\nSklearn Vectors:\")\n",
        "print(f\"Binary F1 Score: {f1_sklearn:.4f}\")\n",
        "print(f\"Binary AUROC: {auroc_sklearn:.4f}\")\n",
        "print(f\"Binary Accuracy: {accuracy_sklearn:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
